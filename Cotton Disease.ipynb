{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1951 images belonging to 4 classes.\n",
      "Found 253 images belonging to 4 classes.\n",
      "Found 106 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "data_gen_train=ImageDataGenerator(rescale=1./255,shear_range=0.2,zoom_range=0.2,horizontal_flip=True)\n",
    "train_set=data_gen_train.flow_from_directory(\"train\",batch_size=32,target_size=(64,64),class_mode=\"categorical\")\n",
    "data_gen_val=ImageDataGenerator(rescale=1./255)\n",
    "val_set=data_gen_val.flow_from_directory(\"val\",batch_size=32,target_size=(64,64),class_mode='categorical')\n",
    "data_gen_test=ImageDataGenerator(rescale=1./255)\n",
    "test_set=data_gen_test.flow_from_directory(\"test\",batch_size=32,target_size=(64,64),class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,Flatten,Conv2D,MaxPool2D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn=Sequential()\n",
    "cnn.add(Conv2D(filters=40,kernel_size=3,activation='relu',input_shape=(64,64,3),padding=\"same\"))\n",
    "cnn.add(MaxPool2D(pool_size=2,strides=2))\n",
    "cnn.add(Conv2D(filters=40,kernel_size=3,activation='relu',input_shape=(64,64,3),padding=\"same\"))\n",
    "cnn.add(MaxPool2D(pool_size=2,strides=2))\n",
    "cnn.add(Flatten())\n",
    "cnn.add(Dense(units=150,activation='relu',kernel_initializer='he_uniform',input_shape=(64,64)))\n",
    "cnn.add(Dense(units=80,activation='relu',kernel_initializer='he_uniform'))\n",
    "cnn.add(Dense(units=4,activation='softmax',kernel_initializer='glorot_uniform'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "61/61 [==============================] - 175s 3s/step - loss: 1.0581 - accuracy: 0.5428 - val_loss: 0.7589 - val_accuracy: 0.6759\n",
      "Epoch 2/10\n",
      "61/61 [==============================] - 197s 3s/step - loss: 0.7482 - accuracy: 0.6981 - val_loss: 0.6989 - val_accuracy: 0.7075\n",
      "Epoch 3/10\n",
      "61/61 [==============================] - 200s 3s/step - loss: 0.6726 - accuracy: 0.7309 - val_loss: 0.7096 - val_accuracy: 0.6996\n",
      "Epoch 4/10\n",
      "61/61 [==============================] - 222s 4s/step - loss: 0.5943 - accuracy: 0.7704 - val_loss: 0.4930 - val_accuracy: 0.8103\n",
      "Epoch 5/10\n",
      "61/61 [==============================] - 237s 4s/step - loss: 0.5184 - accuracy: 0.7950 - val_loss: 0.5284 - val_accuracy: 0.7945\n",
      "Epoch 6/10\n",
      "61/61 [==============================] - 235s 4s/step - loss: 0.5173 - accuracy: 0.7929 - val_loss: 0.3928 - val_accuracy: 0.8458\n",
      "Epoch 7/10\n",
      "61/61 [==============================] - 244s 4s/step - loss: 0.4402 - accuracy: 0.8216 - val_loss: 0.5616 - val_accuracy: 0.7391\n",
      "Epoch 8/10\n",
      "61/61 [==============================] - 236s 4s/step - loss: 0.3967 - accuracy: 0.8488 - val_loss: 0.3840 - val_accuracy: 0.8458\n",
      "Epoch 9/10\n",
      "61/61 [==============================] - 251s 4s/step - loss: 0.3736 - accuracy: 0.8575 - val_loss: 0.5916 - val_accuracy: 0.7391\n",
      "Epoch 10/10\n",
      "61/61 [==============================] - 258s 4s/step - loss: 0.3377 - accuracy: 0.8729 - val_loss: 0.4708 - val_accuracy: 0.8063\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1bb99b4fd90>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn.compile(optimizer='adam',loss=\"categorical_crossentropy\",metrics=['accuracy'])\n",
    "cnn.fit(x=train_set,validation_data=val_set,epochs=10,batch_size=32,shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "cnn.save(\"Model_cotton_disease.h5\")\n",
    "model=load_model(\"Model_cotton_disease.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_2 (Conv2D)            (None, 64, 64, 40)        1120      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 32, 32, 40)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 32, 32, 40)        14440     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 16, 16, 40)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 10240)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 150)               1536150   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 80)                12080     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 4)                 324       \n",
      "=================================================================\n",
      "Total params: 1,564,114\n",
      "Trainable params: 1,564,114\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation on Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 4s 938ms/step - loss: 0.6103 - accuracy: 0.8113\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6102585792541504, 0.8113207817077637]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the model accuracy on individual image inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def op(type,name):\n",
    "    from tensorflow.keras.preprocessing import image\n",
    "    import numpy as np\n",
    "    test_img=image.load_img(f\"test\\{type}\\{name}.jpg\",target_size=(64,64))\n",
    "    test_img=image.img_to_array(test_img)\n",
    "    test_img=test_img/255\n",
    "    test_img=np.expand_dims(test_img,axis=0)\n",
    "    result=model.predict(test_img)\n",
    "    outcome=np.argmax(result)#np.argmax returns the index of max value in that array\n",
    "    if outcome==0:\n",
    "        print(\"Diseased cotton leaf\")\n",
    "    elif outcome==1:\n",
    "        print(\"Diseased cotton plant\")\n",
    "    elif outcome==2:\n",
    "        print(\"Fresh cotton leaf\")\n",
    "    else:\n",
    "        print(\"Fresh cotton plant\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diseased cotton plant\n"
     ]
    }
   ],
   "source": [
    "op(\"diseased cotton plant\",\"dd (41)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
